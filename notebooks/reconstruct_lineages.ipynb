{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sometimes Jupyter notebook doesn't retain your PATH environment variable -- this will mess up a number of things.\n",
    "## We recommend specifying the environment variable manually here\n",
    "import os\n",
    "import ctypes\n",
    "os.environ[\"PATH\"] = '/home/mattjones/bin:/home/mattjones/.local/bin:/home/mattjones/myapps/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/mattjones/opt/gurobi801/linux64/bin:/home/mattjones/software/bowtie2-2.3.4.2:/home/mattjones/emboss/EMBOSS-6.6.0/emboss'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/home/mattjones/lib/::/home/mattjones/opt/gurobi801/linux64/lib'\n",
    "\n",
    "import Cassiopeia.TreeSolver as ts\n",
    "from Cassiopeia.TreeSolver import data_pipeline\n",
    "from Cassiopeia.TreeSolver import post_process_tree as ppt\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle as pic\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleletable_fp = \"lg_output/test.alleleTable.txt\"\n",
    "alleletable = pd.read_csv(alleletable_fp, sep='\\t')\n",
    "target_lg = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Allele Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_props = data_pipeline.get_indel_props(alleletable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create character matrix from a lineage group\n",
    "\n",
    "The first step is to aggregate our observations into a character matrix -- a matrix whose dimensions are `n x m`, where we have `n` cells and `m` characters (total target sites, 3 times the number of integrations in our case). We can use the alleletable_to_character_matrix function here, which takes the following parameters:\n",
    "\n",
    "- **at**: alleletable (subsetted for a particular lineage group) \n",
    "- **out_fp**: the output file path for the resulting character matrix\n",
    "- **mutation_map**: the alleleproprotions, calculated as above. If nothing is provided, no prior probabilities will be used for later tree reconstructions.\n",
    "- **old_r**: Use alleles without context (default = False).\n",
    "\n",
    "This function will write three files: the character matrix, the indel proprotions dictionary, specifying the mutation probabilities for each character to a particular state, and a dictionary translating a state-character pair to an observed allele. The last two files are saved as pickle files, and only written if a mutation_map is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = alleletable[alleletable[\"lineageGrp\"] == target_lg]\n",
    "\n",
    "data_pipeline.alleletable_to_character_matrix(lg, \"test_lg4_character_matrix.txt\", mutation_map=allele_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct a lineage\n",
    "\n",
    "You can now reconstruct lineages using the `reconstruct-lineage` command, which takes in many different commands depending on which of many lineage solvers you'd like to use. We provide Neighbor-Joining, Camin-Sokal (implemented with PHYLIP), greedy, Steiner-Tree/ILP, and Hybrid algorithms. Use the `-h` flag to see all possible parameters.\n",
    "\n",
    "By using one of our algorithms (greedy, hybrid, or ILP), the output will be a networkx object pickle file and a newick text file. The output of the Neighbor-Joining and Camin-Sokal functions is a newick text file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing a Tree\n",
    "\n",
    "Here we'll work with a tree named `test_lg4_tree.pkl`, and we assume it was constructed with the greedy method. In this case, there are two things that need to be done:\n",
    "\n",
    "1. Map terminal character states to the cell identifiers\n",
    "2. Add \"Redundant\" leaves to the terminal leaves. This is necessary because if not ever cell represents a unique state, then the final tree would only be over a subset of the cells originally in the character matrix. This is known as the Post-Processing Tree Step.\n",
    "\n",
    "In the event of post-processing a tree constructed with the hybrid or ilp methods, we only perform step 2. \n",
    "\n",
    "There is also a command-line tool provided for this step, you can call it with `post-process-tree`. Use the `-h` flag to see options and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gpickle(\"test_lg4_tree.pkl\")\n",
    "cm = pd.read_csv(\"test_lg4_character_matrix.txt\", sep='\\t', index_col = 0)\n",
    "\n",
    "g = ppt.assign_samples_to_charstrings(g, cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Process Tree & Add Redundant Leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ppt.post_process_tree(g)\n",
    "g = ppt.add_redundant_leaves(g, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now save final tre\n",
    "out_fp = \"test_lg4_tree.processed.txt\"\n",
    "stem = \".\".join(out_fp.split(\".\")[:-1])\n",
    "\n",
    "pic.dump(g, open(stem + \".pkl\", \"wb\"))\n",
    "\n",
    "newick = data_pipeline.convert_network_to_newick_format(g)\n",
    "\n",
    "with open(out_fp, \"w\") as f:\n",
    "    f.write(newick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
